{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "cb0ad6bc",
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2023-05-13T10:15:33.475957Z",
     "iopub.status.busy": "2023-05-13T10:15:33.474859Z",
     "iopub.status.idle": "2023-05-13T10:15:56.355729Z",
     "shell.execute_reply": "2023-05-13T10:15:56.354376Z"
    },
    "papermill": {
     "duration": 22.895393,
     "end_time": "2023-05-13T10:15:56.358049",
     "exception": false,
     "start_time": "2023-05-13T10:15:33.462656",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/kaggle/input/microsoft-catsvsdogs-dataset/readme[1].txt\n",
      "/kaggle/input/microsoft-catsvsdogs-dataset/PetImages/Dog/7981.jpg\n",
      "/kaggle/input/microsoft-catsvsdogs-dataset/PetImages/Cat/7981.jpg\n"
     ]
    }
   ],
   "source": [
    "# This Python 3 environment comes with many helpful analytics libraries installed\n",
    "# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n",
    "# For example, here's several helpful packages to load\n",
    "\n",
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "import os\n",
    "import torch\n",
    "import torchvision\n",
    "import torch.nn as nn # All neural network modules, nn.Linear, nn.Conv2d, BatchNorm, Loss functions\n",
    "import torchvision.datasets as datasets # Has standard datasets we can import in a nice way\n",
    "import torchvision.transforms as transforms # Transformations we can perform on our dataset\n",
    "import torch.nn.functional as F # All functions that don't have any parameters\n",
    "from torch.utils.data import DataLoader, Dataset # Gives easier dataset managment and creates mini batches\n",
    "from torchvision.datasets import ImageFolder\n",
    "import torch.optim as optim # For all Optimization algorithms, SGD, Adam, etc.\n",
    "from PIL import Image\n",
    "import random\n",
    "import shutil\n",
    "from math import ceil\n",
    "from torchvision.transforms.functional import to_tensor\n",
    "import matplotlib.pyplot as plt\n",
    "# Input data files are available in the read-only \"../input/\" directory\n",
    "# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n",
    "\n",
    "import os\n",
    "for dirname, _, filenames in os.walk('/kaggle/input'):\n",
    "    for filename in filenames:\n",
    "        print(os.path.join(dirname, filename))\n",
    "        break\n",
    "# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n",
    "# You can also write temporhttps://discord.gg/9RMZspGjhttps://discord.gg/9RMZspGjhttps://discord.gg/9RMZspGjary files to /kaggle/temp/, but they won't be saved outside of the current session"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6962ab8f",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-05-13T10:15:56.378320Z",
     "iopub.status.busy": "2023-05-13T10:15:56.376365Z",
     "iopub.status.idle": "2023-05-13T10:15:56.623037Z",
     "shell.execute_reply": "2023-05-13T10:15:56.621498Z"
    },
    "papermill": {
     "duration": 0.258023,
     "end_time": "2023-05-13T10:15:56.624809",
     "exception": true,
     "start_time": "2023-05-13T10:15:56.366786",
     "status": "failed"
    },
    "tags": []
   },
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: '/kaggle/checkpoints'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[2], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mos\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlistdir\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43m/kaggle/checkpoints\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mremove checkpoints\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m      3\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m f \u001b[38;5;129;01min\u001b[39;00m os\u001b[38;5;241m.\u001b[39mlistdir(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m/kaggle/checkpoints\u001b[39m\u001b[38;5;124m'\u001b[39m):\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '/kaggle/checkpoints'"
     ]
    }
   ],
   "source": [
    "os.listdir('/kaggle/checkpoints')\n",
    "print(\"remove checkpoints\")\n",
    "for f in os.listdir('/kaggle/checkpoints'):\n",
    "    f_name = os.path.join('/kaggle/checkpoints',f)\n",
    "    os.remove(f_name)\n",
    "print(\"files in checkpoints/\")\n",
    "os.listdir('/kaggle/checkpoints')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4bd8611",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-05-12T13:07:21.828383Z",
     "iopub.status.busy": "2023-05-12T13:07:21.827509Z",
     "iopub.status.idle": "2023-05-12T13:07:21.835977Z",
     "shell.execute_reply": "2023-05-12T13:07:21.834887Z",
     "shell.execute_reply.started": "2023-05-12T13:07:21.828341Z"
    },
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "os.listdir('/kaggle/checkpoints')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d67872ac",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-05-13T09:52:22.934461Z",
     "iopub.status.busy": "2023-05-13T09:52:22.934076Z",
     "iopub.status.idle": "2023-05-13T09:52:22.943109Z",
     "shell.execute_reply": "2023-05-13T09:52:22.940792Z",
     "shell.execute_reply.started": "2023-05-13T09:52:22.934429Z"
    },
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\") # use gpu or cpu\n",
    "img_size = 224\n",
    "orig_data_path = \"/kaggle/input/microsoft-catsvsdogs-dataset/PetImages/\"\n",
    "train_path = \"/kaggle/dataset/train\"\n",
    "val_path = \"/kaggle/dataset/val\"\n",
    "test_path = \"/kaggle/dataset/test\"\n",
    "saved_models = \"/kaggle/checkpoints\"\n",
    "batch_size = 64\n",
    "classes = ['Dog','Cat']\n",
    "train_ratio = 0.7\n",
    "val_ratio = 0.15\n",
    "test_ratio = 0.15\n",
    "\n",
    "os.mkdir(saved_models)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "716c19e3",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-05-12T12:16:02.527807Z",
     "iopub.status.busy": "2023-05-12T12:16:02.527252Z",
     "iopub.status.idle": "2023-05-12T12:16:02.534280Z",
     "shell.execute_reply": "2023-05-12T12:16:02.533212Z",
     "shell.execute_reply.started": "2023-05-12T12:16:02.527760Z"
    },
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "if not os.path.isdir(saved_models):\n",
    "    os.makedirs(saved_models)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b154e99c",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-05-13T08:51:31.395139Z",
     "iopub.status.busy": "2023-05-13T08:51:31.394447Z",
     "iopub.status.idle": "2023-05-13T08:51:31.410896Z",
     "shell.execute_reply": "2023-05-13T08:51:31.409803Z",
     "shell.execute_reply.started": "2023-05-13T08:51:31.395106Z"
    },
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "len(os.listdir(os.path.join(orig_data_path,\"Dog\")))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed2ff865",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "source": [
    "# Split train-val-test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8aa0391",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-05-13T08:58:54.132155Z",
     "iopub.status.busy": "2023-05-13T08:58:54.131364Z",
     "iopub.status.idle": "2023-05-13T09:02:10.777450Z",
     "shell.execute_reply": "2023-05-13T09:02:10.776439Z",
     "shell.execute_reply.started": "2023-05-13T08:58:54.132117Z"
    },
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "random.seed(42)\n",
    "\n",
    "if os.path.isdir('/kaggle/dataset'):\n",
    "    shutil.rmtree('/kaggle/dataset')\n",
    "else:\n",
    "    print(\"ok\")\n",
    "\n",
    "for target_path in [train_path, val_path, test_path]:\n",
    "    if not os.path.exists(target_path):\n",
    "        os.makedirs(target_path)\n",
    "        for _class in classes:\n",
    "            print(\"class: \",_class)\n",
    "            os.makedirs(os.path.join(target_path, _class))\n",
    "\n",
    "            \n",
    "def is_valid_image_file(filename):\n",
    "    valid_extensions = ('.jpg', '.jpeg', '.png', '.ppm', '.bmp', '.pgm', '.tif', '.tiff', '.webp')\n",
    "    return any(filename.endswith(ext) for ext in valid_extensions)\n",
    "            \n",
    "# split the dataset into train, test\n",
    "for _class in classes:\n",
    "    class_path = os.path.join(orig_data_path, _class)\n",
    "    images = [img for img in os.listdir(class_path) if is_valid_image_file(img)]\n",
    "    #images = os.listdir(class_path)\n",
    "    random.shuffle(images)\n",
    "    \n",
    "    train_images = images[:ceil(len(images) * train_ratio)]\n",
    "    val_images = images[ceil(len(images) * train_ratio):ceil(len(images) * (train_ratio + val_ratio))]\n",
    "    test_images = images[ceil(len(images) * (train_ratio + val_ratio)):]\n",
    "    \n",
    "    print(\"Copying files...\")\n",
    "    for img in train_images:\n",
    "        shutil.copy(os.path.join(class_path, img), os.path.join(train_path, _class, img))\n",
    "    for img in val_images:\n",
    "        shutil.copy(os.path.join(class_path, img), os.path.join(val_path, _class, img)) \n",
    "    for img in test_images:\n",
    "        shutil.copy(os.path.join(class_path, img), os.path.join(test_path, _class, img))                \n",
    "    print(\"Finish\")\n",
    "    \n",
    "    print(f\"Number of train {_class} = {len(os.listdir(os.path.join(train_path, _class)))}\")\n",
    "    print(f\"Number of val {_class} = {len(os.listdir(os.path.join(val_path, _class)))}\")\n",
    "    print(f\"Number of test {_class} = {len(os.listdir(os.path.join(test_path, _class)))}\")\n",
    "print(\"Done\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb630926",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "source": [
    "# Data Loaders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87dad5ed",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-05-13T09:48:27.785211Z",
     "iopub.status.busy": "2023-05-13T09:48:27.784869Z",
     "iopub.status.idle": "2023-05-13T09:48:58.316782Z",
     "shell.execute_reply": "2023-05-13T09:48:58.315630Z",
     "shell.execute_reply.started": "2023-05-13T09:48:27.785182Z"
    },
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# initial checks for images\n",
    "# check image not corrupted\n",
    "class ImageFolderWithFilter(torchvision.datasets.ImageFolder):\n",
    "    def __init__(self, root, transform=None, target_transform=None):\n",
    "        super(ImageFolderWithFilter, self).__init__(root, transform=transform, target_transform=target_transform)\n",
    "        self.samples = self._filter_invalid_images()\n",
    "\n",
    "    def _filter_invalid_images(self):\n",
    "        valid_samples = []\n",
    "        for sample in self.samples:\n",
    "            try:\n",
    "                Image.open(sample[0]).convert(\"RGB\")\n",
    "                valid_samples.append(sample)\n",
    "            except (IOError, SyntaxError) as e:\n",
    "                print(f\"Invalid image: {sample[0]} - {e}\")\n",
    "\n",
    "        return valid_samples\n",
    "\n",
    "\n",
    "\n",
    "# check image not B&W or RGBA\n",
    "class ToTensorEnsure3D:\n",
    "    def __call__(self, pic):\n",
    "        # Convert the image to a 3-channel image if it is grayscale or has an alpha channel\n",
    "        if pic.mode == 'L' or pic.mode == 'RGBA':\n",
    "            pic = pic.convert('RGB')\n",
    "        return to_tensor(pic)\n",
    "\n",
    "simple_transforms = transforms.Compose([\n",
    "    transforms.Resize((img_size, img_size)),\n",
    "    ToTensorEnsure3D(),\n",
    "    transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))\n",
    "])\n",
    "\n",
    "\n",
    "# -----------------------------------------------------------------\n",
    "\n",
    "# Load the datasets with ImageFolderWithFilter and apply the simple_transforms\n",
    "train_dataset = ImageFolderWithFilter(train_path, transform=simple_transforms)\n",
    "val_dataset = ImageFolderWithFilter(val_path, transform=simple_transforms)\n",
    "test_dataset = ImageFolderWithFilter(test_path, transform=simple_transforms)\n",
    "\n",
    "# Create the data loaders\n",
    "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True, num_workers=4)\n",
    "val_loader = DataLoader(val_dataset, batch_size=batch_size, shuffle=True, num_workers=4)\n",
    "test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False, num_workers=4)\n",
    "print(\"Done\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97a45575",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "source": [
    "# Simple NN fully connected"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a34888a4",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-05-13T09:27:48.799180Z",
     "iopub.status.busy": "2023-05-13T09:27:48.798461Z",
     "iopub.status.idle": "2023-05-13T09:27:52.072683Z",
     "shell.execute_reply": "2023-05-13T09:27:52.071642Z",
     "shell.execute_reply.started": "2023-05-13T09:27:48.799146Z"
    },
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class SimpleNet(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(SimpleNet, self).__init__()\n",
    "        self.fc1 = nn.Linear(img_size * img_size * 3, 128)\n",
    "        self.fc2 = nn.Linear(128, 256)\n",
    "        self.fc3 = nn.Linear(256, 2)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = x.view(x.size(0), -1)  # Flatten the input\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = F.relu(self.fc2(x))\n",
    "        x = self.fc3(x)\n",
    "        return F.log_softmax(x, dim=1)\n",
    "\n",
    "# Create the network\n",
    "net = SimpleNet()\n",
    "net.to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e70c53b0",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "source": [
    "# inspect the network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de997fb5",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-05-13T09:28:33.602140Z",
     "iopub.status.busy": "2023-05-13T09:28:33.601525Z",
     "iopub.status.idle": "2023-05-13T09:28:47.640902Z",
     "shell.execute_reply": "2023-05-13T09:28:47.639630Z",
     "shell.execute_reply.started": "2023-05-13T09:28:33.602108Z"
    },
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "!pip install torchsummary\n",
    "from torchsummary import summary\n",
    "\n",
    "# Print the model summary\n",
    "summary(net, input_size=(3, img_size, img_size))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85614359",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-05-12T08:55:03.653442Z",
     "iopub.status.busy": "2023-05-12T08:55:03.652830Z",
     "iopub.status.idle": "2023-05-12T08:55:03.661098Z",
     "shell.execute_reply": "2023-05-12T08:55:03.660024Z",
     "shell.execute_reply.started": "2023-05-12T08:55:03.653395Z"
    },
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "img_size * img_size * 128 * 3 + 128"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c22c593",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "source": [
    "# Training loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d4632b1",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-05-13T09:46:42.444394Z",
     "iopub.status.busy": "2023-05-13T09:46:42.444017Z",
     "iopub.status.idle": "2023-05-13T09:46:42.461869Z",
     "shell.execute_reply": "2023-05-13T09:46:42.460954Z",
     "shell.execute_reply.started": "2023-05-13T09:46:42.444360Z"
    },
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import time\n",
    "\n",
    "def train(model, nb_epochs, name_model):\n",
    "    train_losses = []\n",
    "    val_losses = []\n",
    "    train_accuracies = []\n",
    "    val_accuracies = []\n",
    "    \n",
    "    \n",
    "    start = time.time()\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr = 0.001)\n",
    "\n",
    "    for epoch in range(nb_epochs):\n",
    "\n",
    "        epoch_loss = 0\n",
    "        epoch_accuracy = 0\n",
    "        \n",
    "        for X, y in train_loader:\n",
    "            X = X.to(device)\n",
    "            y = y.to(device)\n",
    "            preds = model(X)\n",
    "            loss = criterion(preds, y)\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            accuracy = ((preds.argmax(dim=1) == y).float().mean())\n",
    "            epoch_accuracy += accuracy.item()\n",
    "            epoch_loss += loss.item()\n",
    "            \n",
    "            print('.', end='', flush=True)\n",
    "\n",
    "        epoch_accuracy = epoch_accuracy/len(train_loader)\n",
    "        train_accuracies.append(epoch_accuracy)\n",
    "        epoch_loss = epoch_loss / len(train_loader)\n",
    "        train_losses.append(epoch_loss)\n",
    "\n",
    "        print(\"\\n --- Epoch: {}, train loss: {:.4f}, train acc: {:.4f}, time: {}\".format(epoch, epoch_loss, epoch_accuracy, time.time() - start))\n",
    "        # save model\n",
    "        save_name = os.path.join(saved_models, name_model +'_checkpoint_epoch_'+str(epoch)+'.pt')\n",
    "        print(f\"saved checkpoint {save_name}\")\n",
    "        torch.save({ \n",
    "                    'model_state_dict': model.state_dict(), \n",
    "                    'optimizer_state_dict': optimizer.state_dict(), \n",
    "                    }, save_name)\n",
    "        \n",
    "        '''\n",
    "        torch.save({ \n",
    "                    'model_state_dict': model.state_dict(), \n",
    "                    'optimizer_state_dict': optimizer.state_dict(), \n",
    "                    }, 'checpoint_epoch_'+str(epoch)+'.pt')\n",
    "        '''\n",
    "        # test set accuracy\n",
    "        with torch.no_grad():\n",
    "\n",
    "            val_epoch_loss = 0\n",
    "            val_epoch_accuracy = 0\n",
    "\n",
    "            for val_X, val_y in val_loader:\n",
    "                val_X = val_X.to(device)\n",
    "                val_y = val_y.to(device)\n",
    "                val_preds = model(val_X)\n",
    "                val_loss = criterion(val_preds, val_y)\n",
    "\n",
    "                val_epoch_loss += val_loss.item()            \n",
    "                val_accuracy = ((val_preds.argmax(dim=1) == val_y).float().mean())\n",
    "                val_epoch_accuracy += val_accuracy.item()\n",
    "\n",
    "            val_epoch_accuracy = val_epoch_accuracy/len(val_loader)\n",
    "            val_epoch_loss = val_epoch_loss / len(val_loader)\n",
    "            val_losses.append(val_epoch_loss)\n",
    "            val_accuracies.append(val_epoch_accuracy)\n",
    "            print(\"Epoch: {}, val loss: {:.4f}, val acc: {:.4f}, time: {}\\n\".format(epoch, val_epoch_loss, val_epoch_accuracy, time.time() - start))\n",
    "            \n",
    "        \n",
    "    # Plot the training and validation losses\n",
    "    plt.plot(train_losses, label='Training Loss')\n",
    "    plt.plot(val_losses, label='Validation Loss')\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.ylabel('Loss')\n",
    "    plt.title('Training and Validation Loss per Epoch')\n",
    "    plt.legend()\n",
    "    \n",
    "    plt.plot(train_accuracies, label='Training Acc')\n",
    "    plt.plot(val_accuracies, label='Validation Acc')\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.ylabel('Accuracy')\n",
    "    plt.title('Training and Validation Acc per Epoch')\n",
    "    plt.legend()\n",
    "    \n",
    "    \n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8a32947",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "source": [
    "# Testing loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb9d5e35",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-05-13T09:47:56.732251Z",
     "iopub.status.busy": "2023-05-13T09:47:56.731520Z",
     "iopub.status.idle": "2023-05-13T09:47:56.741111Z",
     "shell.execute_reply": "2023-05-13T09:47:56.739790Z",
     "shell.execute_reply.started": "2023-05-13T09:47:56.732214Z"
    },
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def test(model):\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    model.eval()\n",
    "    test_loss = 0\n",
    "    correct = 0\n",
    "    with torch.no_grad():\n",
    "        for x, y in test_loader:\n",
    "            x = x.to(device)\n",
    "            y = y.to(device)\n",
    "            output = model(x)\n",
    "            _, predictions = torch.max(output, 1)\n",
    "            correct += (predictions == y).sum().item()\n",
    "            test_loss = criterion(output, y)\n",
    "            \n",
    "    test_loss /= len(test_loader.dataset)\n",
    "    print(\"Average Loss: \", test_loss, \"  Accuracy: \", correct, \" / \",\n",
    "    len(test_loader.dataset), \"  \", int(correct / len(test_loader.dataset) * 100), \"%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2115c2a",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-05-13T09:52:33.074740Z",
     "iopub.status.busy": "2023-05-13T09:52:33.074292Z",
     "iopub.status.idle": "2023-05-13T10:05:05.304956Z",
     "shell.execute_reply": "2023-05-13T10:05:05.303810Z",
     "shell.execute_reply.started": "2023-05-13T09:52:33.074707Z"
    },
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "train(net,10, 'simple_fc')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "491ffe40",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-05-12T13:27:40.200305Z",
     "iopub.status.busy": "2023-05-12T13:27:40.199847Z",
     "iopub.status.idle": "2023-05-12T13:27:50.487170Z",
     "shell.execute_reply": "2023-05-12T13:27:50.486117Z",
     "shell.execute_reply.started": "2023-05-12T13:27:40.200253Z"
    },
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "test(net)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "389e5ebc",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "source": [
    "# Chenge to a CNN model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "377f68b9",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-05-13T10:09:48.160974Z",
     "iopub.status.busy": "2023-05-13T10:09:48.160520Z",
     "iopub.status.idle": "2023-05-13T10:09:48.743289Z",
     "shell.execute_reply": "2023-05-13T10:09:48.742330Z",
     "shell.execute_reply.started": "2023-05-13T10:09:48.160938Z"
    },
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class CatDogCNN(nn.Module):\n",
    "    def __init__(self, img_size):\n",
    "        super(CatDogCNN, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(3, 32, 3, padding=1)\n",
    "        self.conv2 = nn.Conv2d(32, 64, 3, padding=1)\n",
    "        self.conv3 = nn.Conv2d(64, 128, 3, padding=1)\n",
    "        self.pool = nn.MaxPool2d(2, 2)\n",
    "        reduced_size = img_size // 2**3  # Calculate the reduced size after three pooling layers\n",
    "        self.fc1 = nn.Linear(128 * reduced_size * reduced_size, 512)\n",
    "        self.fc2 = nn.Linear(512, 2)\n",
    "        self.dropout = nn.Dropout(0.5)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.pool(F.relu(self.conv1(x)))\n",
    "        x = self.pool(F.relu(self.conv2(x)))\n",
    "        x = self.pool(F.relu(self.conv3(x)))\n",
    "        x = x.view(x.size(0), -1)  # Flatten the tensor\n",
    "        x = self.dropout(x)\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = self.dropout(x)\n",
    "        x = self.fc2(x)\n",
    "        return F.log_softmax(x, dim=1)\n",
    "\n",
    "net = CatDogCNN(img_size)\n",
    "net.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a7a53dd",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-05-13T10:10:01.030730Z",
     "iopub.status.busy": "2023-05-13T10:10:01.030342Z"
    },
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "train(net,10, 'our_CNN')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88bb7803",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "test(net)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d55b8d4b",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "source": [
    "# A pre-trained model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f955aac",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-05-11T17:54:25.497090Z",
     "iopub.status.busy": "2023-05-11T17:54:25.496598Z"
    },
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "from torchvision import models\n",
    "model = models.resnet50(pretrained=True)\n",
    "for param in model.parameters():\n",
    "    param.requires_grad = False\n",
    "\n",
    "num_ftrs = model.fc.in_features\n",
    "model.fc = nn.Linear(num_ftrs, 2)\n",
    "\n",
    "model.to(device)\n",
    "\n",
    "train(model, 10, \"pretrained\")\n",
    "test(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8f3a3b7",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def RandomImagePrediction(filepath, model):\n",
    "    img_array = Image.open(filepath).convert(\"RGB\")\n",
    "    real_class = filepath.split(\"/\")[3]\n",
    "    \n",
    "    \n",
    "    data_transforms=transforms.Compose([\n",
    "        transforms.Resize((224, 224)), \n",
    "        transforms.ToTensor(), \n",
    "        transforms.Normalize([0.5]*3, [0.5]*3)\n",
    "    ])\n",
    "    img = data_transforms(img_array).unsqueeze(dim=0) # Returns a new tensor with a dimension of size one inserted at the specified position.\n",
    "    load = DataLoader(img)\n",
    "    \n",
    "    for x in load:\n",
    "        x=x.to(device)\n",
    "        pred = model(x)\n",
    "        _, preds = torch.max(pred, 1)\n",
    "        #print(f\"class : {preds}\")\n",
    "        if preds[0] == 1: print(f\"real class {real_class} and predicted ----> Dog\")\n",
    "        else: print(f\"real class {real_class} and predicted ----> Cat\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b80986a1",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "RandomImagePrediction(\"/tmp/test/Cat/11.jpg\", net)\n",
    "RandomImagePrediction(\"/tmp/test/Cat/48.jpg\", net)\n",
    "RandomImagePrediction(\"/tmp/test/Cat/75.jpg\", net)\n",
    "RandomImagePrediction(\"/tmp/test/Cat/88.jpg\", net)\n",
    "RandomImagePrediction(\"/tmp/test/Cat/104.jpg\", net)\n",
    "RandomImagePrediction(\"/tmp/test/Dog/2.jpg\", net)\n",
    "RandomImagePrediction(\"/tmp/test/Dog/6.jpg\", net)\n",
    "RandomImagePrediction(\"/tmp/test/Dog/7.jpg\", net)\n",
    "RandomImagePrediction(\"/tmp/test/Dog/11.jpg\", net)\n",
    "RandomImagePrediction(\"/tmp/test/Dog/14.jpg\", net)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc90baae",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "source": [
    "# Try with a pre-trained model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f61c657",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "from torchvision import models\n",
    "model = models.resnet18(pretrained=True)\n",
    "for param in model.parameters():\n",
    "    param.requires_grad = False\n",
    "\n",
    "num_ftrs = model.fc.in_features\n",
    "model.fc = nn.Linear(num_ftrs, 2)\n",
    "\n",
    "model.to(device)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 36.87551,
   "end_time": "2023-05-13T10:15:59.205972",
   "environment_variables": {},
   "exception": true,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2023-05-13T10:15:22.330462",
   "version": "2.4.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
